{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:54.862869Z",
     "start_time": "2025-06-08T14:25:54.424893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import h3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import git\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import shapely.geometry\n",
    "from pyproj import Transformer\n",
    "from pyproj import Geod\n",
    "from shapely.ops import transform\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.patches import Circle"
   ],
   "id": "e14aa726077157c3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:54.961165Z",
     "start_time": "2025-06-08T14:25:54.959524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# H3 cell areas by resolution (in m^2)\n",
    "h3_areas = {res: h3.average_hexagon_area(res, unit=\"m^2\") for res in range(16)}  # resolutions 0â€“15\n",
    "\n",
    "# Function to get lowest H3 resolution that fits the area\n",
    "def get_h3_resolution_for_area(area_m2):\n",
    "    for res in sorted(h3_areas, reverse=True):\n",
    "        if h3_areas[res] >= area_m2:\n",
    "            return res\n",
    "    return 5  # fallback to 5"
   ],
   "id": "13d741fc20fe82ca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:54.973562Z",
     "start_time": "2025-06-08T14:25:54.970823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def safe_latlng_to_cell(x):\n",
    "    geor = x.get(\"georelated\")\n",
    "    if not geor:\n",
    "        return None\n",
    "    if isinstance(geor, dict):\n",
    "        center = geor.get(\"center coordinates of affected area\")\n",
    "        area = geor.get(\"affected area in square km\")\n",
    "        if center is None:\n",
    "            center = geor.get(\"center_coordinates_of_affected_area\")\n",
    "        if area is None:\n",
    "            area = geor.get(\"affected_area_in_square_km\")\n",
    "    else:\n",
    "        center = None\n",
    "        area = None\n",
    "    if not center:\n",
    "        return None\n",
    "    lat = center.get(\"latitude\") if isinstance(center, dict) else None\n",
    "    lng = center.get(\"longitude\") if isinstance(center, dict) else None\n",
    "    if lat is None or lng is None or area is None:\n",
    "        return None\n",
    "    try:\n",
    "        return h3.latlng_to_cell(\n",
    "            lat=float(lat),\n",
    "            lng=float(lng),\n",
    "            res=get_h3_resolution_for_area(float(area) * 1e6),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_cell_relation(pred_cell, trajector_cell_index) -> str:\n",
    "    \"\"\"\n",
    "    Determines the relationship between two H3 cells.\n",
    "    :param pred_cell: The predicted H3 cell.\n",
    "    :param trajector_cell_index: The ground truth H3 cell.\n",
    "    :return: A string indicating the relationship.\n",
    "    \"\"\"\n",
    "\n",
    "    if pred_cell == trajector_cell_index:\n",
    "        return \"identical\"\n",
    "\n",
    "    # Get their resolutions\n",
    "    pred_res = h3.get_resolution(pred_cell)\n",
    "    gt_res = h3.get_resolution(trajector_cell_index)\n",
    "\n",
    "    if pred_res == gt_res:\n",
    "        if h3.are_neighbor_cells(pred_cell, trajector_cell_index):\n",
    "            return \"same_resolution_neighbor\"\n",
    "        else:\n",
    "            return \"disjoint_same_resolution\"\n",
    "    elif pred_res < gt_res:\n",
    "        inferred_parent = h3.cell_to_parent(trajector_cell_index, pred_res)\n",
    "        if pred_cell == inferred_parent:\n",
    "            return \"parent\"\n",
    "        else:\n",
    "            if h3.are_neighbor_cells(pred_cell, inferred_parent):\n",
    "                return \"coarser_neighbor\"\n",
    "            return \"disjoint_coarser_resolution\"\n",
    "    else:\n",
    "        inferred_parent = h3.cell_to_parent(pred_cell, gt_res)\n",
    "        if trajector_cell_index == inferred_parent:\n",
    "            return \"child\"\n",
    "        else:\n",
    "            if h3.are_neighbor_cells(trajector_cell_index, inferred_parent):\n",
    "                return \"finer_neighbor\"\n",
    "            return \"disjoint_finer_resolution\""
   ],
   "id": "99e50fb296108ad8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:54.986529Z",
     "start_time": "2025-06-08T14:25:54.980310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics(df, k=50):\n",
    "    \"\"\"\n",
    "    Calculate various metrics for the georelated DataFrame.\n",
    "    :param df: DataFrame containing georelated data.\n",
    "    :param k: Accuracy threshold in km.\n",
    "    :return: Dictionary of calculated metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    project = Transformer.from_crs('epsg:4326', 'epsg:6933', always_xy=True).transform\n",
    "\n",
    "    # Prepare DataFrame columns for results (if not present)\n",
    "    for col in [\"error_distance\", \"pred_area_6933\", \"gt_area_6933\", \"intersection_area_6933\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    all_log_q_area = []\n",
    "    all_log_q_distance = []\n",
    "\n",
    "    # Initialize counts\n",
    "    counts = {\n",
    "        'identical': 0,\n",
    "        'parent': 0,\n",
    "        'child': 0,\n",
    "        'coarser_neighbor': 0,\n",
    "        'same_resolution_neighbor': 0,\n",
    "        'finer_neighbor': 0,\n",
    "        'disjoint_same_resolution': 0,\n",
    "        'disjoint_coarser_resolution': 0,\n",
    "        'disjoint_finer_resolution': 0\n",
    "    }\n",
    "\n",
    "    # Calculate all metrics row-wise, store in DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        if row.get('pred_cell') is None or row.get('trajector_cell_index') is None:\n",
    "            continue\n",
    "\n",
    "        # Parse coordinates\n",
    "        gt_lat, gt_lon = map(float, map(str.strip, row[\"trajector_center\"].split(\",\")))\n",
    "        gt_coordinates = (gt_lat, gt_lon)\n",
    "        try:\n",
    "            pred_center = row['georelated']['center coordinates of affected area']\n",
    "        except KeyError as e:\n",
    "            pred_center = row['georelated']['center_coordinates_of_affected_area']\n",
    "        predicted_coordinates = (pred_center['latitude'], pred_center['longitude'])\n",
    "\n",
    "        # Geodesic error in km\n",
    "        error_distance = geodesic(gt_coordinates, predicted_coordinates).kilometers\n",
    "        df.at[index, \"error_distance\"] = error_distance\n",
    "\n",
    "        # H3 cell shapes\n",
    "        pred_shape = h3.cells_to_h3shape([row['pred_cell']])\n",
    "        target_shape = h3.cells_to_h3shape([row['trajector_cell_index']])\n",
    "        pred_poly = shapely.geometry.shape(h3.h3shape_to_geo(pred_shape))\n",
    "        target_poly = shapely.geometry.shape(h3.h3shape_to_geo(target_shape))\n",
    "\n",
    "        # Project to equal-area CRS\n",
    "        pred_poly_proj = transform(project, pred_poly)\n",
    "        target_poly_proj = transform(project, target_poly)\n",
    "        pred_area_m2 = pred_poly_proj.area\n",
    "        gt_area_m2   = target_poly_proj.area\n",
    "\n",
    "        df.at[index, \"pred_area_6933\"] = pred_area_m2\n",
    "        df.at[index, \"gt_area_6933\"] = gt_area_m2\n",
    "\n",
    "        # Intersection area\n",
    "        intersection = pred_poly_proj.intersection(target_poly_proj)\n",
    "        intersection_area = intersection.area\n",
    "        df.at[index, \"intersection_area_6933\"] = intersection_area\n",
    "\n",
    "        relation = row['cell_relation']\n",
    "        if relation in counts:\n",
    "            counts[relation] += 1\n",
    "\n",
    "        # Calculate proportion metrics for this row\n",
    "        try:\n",
    "            log_q_area = np.log(pred_area_m2 / gt_area_m2)\n",
    "            all_log_q_area.append(log_q_area)\n",
    "            # if not nan\n",
    "            if not np.isnan(row['distance_to_landmark']):\n",
    "                denom = row['distance_to_landmark'] + 1e-5\n",
    "                numer = row['pred_distance']\n",
    "\n",
    "                if denom <= 0 or numer <= 0:\n",
    "                    log_q_distance = np.nan\n",
    "                else:\n",
    "                    log_q_distance = np.log(numer / denom)\n",
    "                all_log_q_distance.append(log_q_distance)\n",
    "        except Exception:\n",
    "            all_log_q_area.append(np.nan)\n",
    "\n",
    "    ####### Aggregate Metrics ########\n",
    "\n",
    "    # Remove NaNs\n",
    "    all_error_distances = df[\"error_distance\"].dropna().values\n",
    "    all_log_q_area = np.array([x for x in all_log_q_area if not np.isnan(x)])\n",
    "    all_log_q_distance = np.array([x for x in all_log_q_distance if not np.isnan(x)])\n",
    "\n",
    "    # ACCURACY@k\n",
    "    within_k = (all_error_distances <= k)\n",
    "    accuracy_at_k = within_k.mean()\n",
    "    strict_accuracy_at_k = np.sum(within_k) / len(df)\n",
    "\n",
    "    def calculate_auc(sorted_values):\n",
    "        max_error = 20038  # Earth's circumference in km / 2\n",
    "        size = len(sorted_values)\n",
    "        if size <= 1:\n",
    "            return 0.0\n",
    "        h = 1  # step size\n",
    "        log_max = np.log(max_error)\n",
    "        auc = 0.5 * ((np.log(1 + sorted_values[0]) + np.log(1 + sorted_values[-1])) / log_max)\n",
    "        for v in sorted_values[1:-1]:\n",
    "            auc += np.log(1 + v) / log_max\n",
    "        auc = auc * h / (size - 1)\n",
    "        return auc\n",
    "\n",
    "    sorted_error_distances = np.sort(all_error_distances)\n",
    "    auc = calculate_auc(sorted_error_distances)\n",
    "\n",
    "    # Mean/Median error\n",
    "    mean_error_distance = np.mean(all_error_distances)\n",
    "    median_error_distance = np.median(all_error_distances)\n",
    "\n",
    "    # Î¶ Median Symmetric Accuracy\n",
    "    zeta = 100 * (np.exp(np.median(np.abs(all_log_q_area))) - 1)\n",
    "\n",
    "    # SSPB\n",
    "    sspb = 100 * np.sign(np.median(all_log_q_area)) * (np.exp(np.abs(np.median(all_log_q_area))) - 1)\n",
    "\n",
    "    valid = (\n",
    "        (df['intersection_area_6933'] > 0) &\n",
    "        (df['pred_area_6933'] > 0) &\n",
    "        (df['gt_area_6933'] > 0)\n",
    "    )\n",
    "    average_precision = (df.loc[valid, 'intersection_area_6933'] / df.loc[valid, 'pred_area_6933']).mean()\n",
    "    average_recall = (df.loc[valid, 'intersection_area_6933'] / df.loc[valid, 'gt_area_6933']).mean()\n",
    "    average_f1 = 2 * average_precision * average_recall / (average_precision + average_recall)\n",
    "\n",
    "    # distance metrics\n",
    "    # Î¶ Median Symmetric Accuracy\n",
    "    zeta_distance = 100 * (np.exp(np.median(np.abs(all_log_q_distance))) - 1)\n",
    "\n",
    "    # SSPB\n",
    "    sspb_distance = 100 * np.sign(np.median(all_log_q_distance)) * (np.exp(np.abs(np.median(all_log_q_distance))) - 1)\n",
    "\n",
    "\n",
    "    # Calculate cell-based metrics\n",
    "    total = sum(counts.values())\n",
    "    fuzzy_cell_match_score = 1 - (counts['disjoint_coarser_resolution'] + counts['disjoint_finer_resolution'] + counts['disjoint_same_resolution']) / total if total else 0\n",
    "    exact_cell_match_score = counts['identical'] / total if total else 0\n",
    "    cell_overlap_score = (counts['parent'] + counts['child'] + counts['identical']) / total if total else 0\n",
    "    cell_level_accuracy = (counts['identical'] + counts['disjoint_same_resolution'] + counts['same_resolution_neighbor']) / total if total else 0\n",
    "    count_finer = counts['child'] + counts['finer_neighbor'] + counts['disjoint_finer_resolution']\n",
    "    count_coarser = counts['parent'] + counts['coarser_neighbor'] + counts['disjoint_coarser_resolution']\n",
    "    cell_level_bias = (count_coarser - count_finer) / total if total else 0\n",
    "\n",
    "    # Return all metrics\n",
    "    return {\n",
    "        'fuzzy_cell_match_score': fuzzy_cell_match_score,\n",
    "        'exact_cell_match_score': exact_cell_match_score,\n",
    "        'cell_overlap_score': cell_overlap_score,\n",
    "        'cell_level_accuracy': cell_level_accuracy,\n",
    "        'cell_level_bias': cell_level_bias,\n",
    "        f\"accuracy@{k}\": accuracy_at_k,\n",
    "        f\"strict_accuracy@{k}\": strict_accuracy_at_k,\n",
    "        \"auc\": auc,\n",
    "        \"mean_error_distance\": mean_error_distance,\n",
    "        \"median_error_distance\": median_error_distance,\n",
    "        \"area_zeta\": zeta,\n",
    "        \"area_sspb\": sspb,\n",
    "        \"average_precision\": average_precision,\n",
    "        \"average_recall\": average_recall,\n",
    "        \"average_f1\": average_f1,\n",
    "        \"distance_zeta\": zeta_distance,\n",
    "        \"distance_sspb\": sspb_distance\n",
    "    }"
   ],
   "id": "2700afa5b2bde3bb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:54.993432Z",
     "start_time": "2025-06-08T14:25:54.991530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_azimuth_distance(row, geod=Geod(ellps=\"WGS84\")):\n",
    "    try:\n",
    "        # Check if coordinates are missing (None or not a dict)\n",
    "        center = row[\"georelated\"].get(\"center coordinates of affected area\")\n",
    "        if center is None:\n",
    "            center = row[\"georelated\"].get(\"center_coordinates_of_affected_area\")\n",
    "        if center is None:\n",
    "            return pd.Series({'forward_azimuth': None, 'pred_distance': None})\n",
    "        fwd_azimuth, _, dist = geod.inv(\n",
    "            row[\"landmark_longitude\"],\n",
    "            row[\"landmark_latitude\"],\n",
    "            center[\"longitude\"],\n",
    "            center[\"latitude\"]\n",
    "        )\n",
    "        # Normalize azimuth to 0-360Â°\n",
    "        fwd_azimuth = (fwd_azimuth + 360) % 360\n",
    "        return pd.Series({'forward_azimuth': fwd_azimuth, 'pred_distance': dist})\n",
    "    except Exception:\n",
    "        # Catch possible missing keys or bad values\n",
    "        return pd.Series({'forward_azimuth': None, 'pred_distance': None})"
   ],
   "id": "d0849486e5ef25b9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:55.008694Z",
     "start_time": "2025-06-08T14:25:55.001088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compass_dirs = {\n",
    "    'north': (337.5, 22.5),\n",
    "    'northeast': (22.5, 67.5),\n",
    "    'east': (67.5, 112.5),\n",
    "    'southeast': (112.5, 157.5),\n",
    "    'south': (157.5, 202.5),\n",
    "    'southwest': (202.5, 247.5),\n",
    "    'west': (247.5, 292.5),\n",
    "    'northwest': (292.5, 337.5)\n",
    "}\n",
    "\n",
    "dir_colors = {\n",
    "    'north': '#b2182b',\n",
    "    'northeast': '#f1b6da',\n",
    "    'east': '#c51b7d',\n",
    "    'southeast': '#9970ab',\n",
    "    'south': '#2166ac',\n",
    "    'southwest': '#80cdc1',\n",
    "    'west': '#1a7837',\n",
    "    'northwest': '#dfc27d'\n",
    "}\n",
    "\n",
    "def azimuth_to_direction(azimuth):\n",
    "    if np.isnan(azimuth):\n",
    "        return np.nan\n",
    "    for direction, (start, end) in compass_dirs.items():\n",
    "        if start > end:\n",
    "            if azimuth >= start or azimuth < end:\n",
    "                return direction\n",
    "        else:\n",
    "            if start <= azimuth < end:\n",
    "                return direction\n",
    "    return 'north'\n",
    "\n",
    "def plot_azimuth_visualization(\n",
    "    df,\n",
    "    azimuth_bin_size=15,\n",
    "    distance_bin_size=0.1,\n",
    "    upper_bound=0.9,\n",
    "    lower_bound=0.1,\n",
    "    focus_directions=None,\n",
    "    plot_type='all_in_one',\n",
    "    viz_file_name=None,\n",
    "):\n",
    "\n",
    "    df['distance_ratio'] = df[\"pred_distance\"] / df[\"distance_to_landmark\"]\n",
    "    lower_bound = df['distance_ratio'].quantile(lower_bound)\n",
    "    upper_bound = df['distance_ratio'].quantile(upper_bound)\n",
    "    df = df[(df['distance_ratio'] >= lower_bound) & (df['distance_ratio'] <= upper_bound)]\n",
    "\n",
    "    df['azimuth_bin'] = (df['forward_azimuth'] // azimuth_bin_size * azimuth_bin_size).astype(int)\n",
    "    df['ratio_bin'] = (df['distance_ratio'] // distance_bin_size * distance_bin_size).round(2)\n",
    "    df['gt_direction'] = df['azimuth'].apply(azimuth_to_direction)\n",
    "\n",
    "    grouped = df.groupby(['azimuth_bin', 'ratio_bin', 'gt_direction']).size().reset_index(name='count')\n",
    "    grouped['theta'] = np.deg2rad(grouped['azimuth_bin'])\n",
    "    grouped['r'] = grouped['ratio_bin']\n",
    "    inner_radius = 0.1\n",
    "    grouped['r_plot'] = grouped['r'] + inner_radius\n",
    "    grouped['bin_idx'] = grouped.groupby('azimuth_bin').cumcount()\n",
    "    grouped['theta_offset'] = grouped['bin_idx'] * (azimuth_bin_size * np.pi / 180) / 10\n",
    "    grouped['theta_final'] = grouped['theta'] + grouped['theta_offset'] - grouped['theta_offset'].mean()\n",
    "    max_count = grouped['count'].max()\n",
    "    min_width = 0.005\n",
    "    grouped['width'] = np.maximum((grouped['count'] / max_count) * (azimuth_bin_size * np.pi / 180) * 0.9, min_width)\n",
    "\n",
    "    sns.set_theme(style=\"white\", context=\"notebook\", font_scale=1.2)\n",
    "    if plot_type == 'all_in_one':\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(12, 12), facecolor='w')\n",
    "\n",
    "        # Draw ground truth reference circle with radius (1.0 + inner_radius)\n",
    "        theta_line = np.linspace(0, 2*np.pi, 360)\n",
    "        ax.plot(theta_line, np.full_like(theta_line, 1.0 + inner_radius), \"k-\", linewidth=1.5)\n",
    "\n",
    "        for _, row in grouped.iterrows():\n",
    "            color = dir_colors.get(row['gt_direction'], 'gray')\n",
    "            ax.bar(\n",
    "                x=row['theta_final'],\n",
    "                height=row['r'],\n",
    "                width=row['width'],\n",
    "                bottom=inner_radius,\n",
    "                color=color,\n",
    "                alpha=1.0,\n",
    "                edgecolor='none'\n",
    "            )\n",
    "\n",
    "        ax.set_theta_zero_location(\"N\")\n",
    "        ax.set_theta_direction(\"clockwise\")\n",
    "        r_max = grouped['r_plot'].max() + 0.1\n",
    "        ax.set_ylim(0, r_max)\n",
    "\n",
    "        tick_locations = [inner_radius + x for x in [0, 0.5, 1.0, 1.5, 2.0, 2.5]]\n",
    "        ax.set_yticks(tick_locations)\n",
    "        ax.set_yticklabels([f\"{(t - inner_radius)*100:.0f}%\" for t in tick_locations])\n",
    "        ax.set_rlabel_position(15)\n",
    "\n",
    "        for label in ax.get_yticklabels():\n",
    "            if label.get_text() == \"100%\":\n",
    "                label.set_fontweight(\"bold\")\n",
    "\n",
    "        ax.set_title(\"Model Performance by Azimuth\\n\", fontsize=18, fontweight='bold')\n",
    "\n",
    "        circle = Circle((0, 0), inner_radius, transform=ax.transData._b, facecolor='white', edgecolor='none', zorder=5)\n",
    "        ax.add_artist(circle)\n",
    "\n",
    "        ytick_lines = [\n",
    "            Line2D([0], [0], color=\"gray\", linewidth=1.5, label=\"0%: prediction on landmark\"),\n",
    "            Line2D([0], [0], color=\"gray\", linewidth=1.5, label=\"0 < r < 100%: prediction too short\"),\n",
    "            Line2D([0], [0], color=\"black\", linewidth=1.5, label=\"100%: prediction == true distance\"),\n",
    "            Line2D([0], [0], color=\"gray\", linewidth=1.5, label=\"r > 100%: prediction too long\")\n",
    "        ]\n",
    "\n",
    "        distance_ratio_legend = ax.legend(\n",
    "            handles=ytick_lines,\n",
    "            title=\"Trajector distance ratio\",\n",
    "            loc='lower center', bbox_to_anchor=(0.89, 0.9), ncol=1\n",
    "        )\n",
    "        distance_ratio_legend.get_title().set_ha('center')\n",
    "        distance_ratio_legend.set_title(\"Trajector distance ratio\", prop={'weight':'bold'})\n",
    "        ax.add_artist(distance_ratio_legend)\n",
    "\n",
    "        legend_patches = [Patch(color=color, label=dir.title()) for dir, color in dir_colors.items()]\n",
    "        ax.legend(handles=legend_patches,\n",
    "                  title=\"Ground truth direction\",\n",
    "                  loc='lower center',\n",
    "                  bbox_to_anchor=(0.5, -0.11), ncol=4)\n",
    "        ax.get_legend().get_title().set_fontweight('bold')\n",
    "        ax.set_xticks(np.deg2rad([0, 90, 180, 270]))\n",
    "        ax.set_xticklabels(['North', 'East', 'South', 'West'], fontsize=12, ha='center')\n",
    "        ax.spines['polar'].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    elif plot_type == 'subplots':\n",
    "        if focus_directions is None:\n",
    "            focus_directions = list(compass_dirs.keys())\n",
    "\n",
    "        num_directions = len(focus_directions)\n",
    "        fig, axes = plt.subplots(num_directions, 1, subplot_kw={'projection': 'polar'}, figsize=(5, num_directions * 5))\n",
    "        plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "        if num_directions == 1:\n",
    "            axes = [axes]  # Fix the axes in case there's only one subplot\n",
    "\n",
    "        for i, direction in enumerate(focus_directions):\n",
    "            df_dir = df[df['gt_direction'] == direction]\n",
    "\n",
    "            grouped_dir = df_dir.groupby(['azimuth_bin', 'ratio_bin', 'gt_direction']).size().reset_index(name='count')\n",
    "            grouped_dir['theta'] = np.deg2rad(grouped_dir['azimuth_bin'])\n",
    "            grouped_dir['r'] = grouped_dir['ratio_bin']\n",
    "            grouped_dir['r_plot'] = grouped_dir['r'] + inner_radius\n",
    "\n",
    "            grouped_dir['bin_idx'] = grouped_dir.groupby('azimuth_bin').cumcount()\n",
    "            grouped_dir['theta_offset'] = grouped_dir['bin_idx'] * (azimuth_bin_size * np.pi / 180) / 10\n",
    "            grouped_dir['theta_final'] = grouped_dir['theta'] + grouped_dir['theta_offset'] - grouped_dir['theta_offset'].mean()\n",
    "\n",
    "            max_count_dir = grouped_dir['count'].max()\n",
    "            grouped_dir['width'] = np.maximum((grouped_dir['count'] / max_count_dir) * (azimuth_bin_size * np.pi / 180) * 0.9, min_width)\n",
    "\n",
    "            ax = axes[i]\n",
    "            theta_line = np.linspace(0, 2*np.pi, 360)\n",
    "            ax.plot(theta_line, np.full_like(theta_line, 1.0 + inner_radius), \"k-\", linewidth=1.5)\n",
    "\n",
    "            for _, row in grouped_dir.iterrows():\n",
    "                color = dir_colors.get(row['gt_direction'], 'gray')\n",
    "                ax.bar(\n",
    "                    x=row['theta_final'],\n",
    "                    height=row['r'],\n",
    "                    width=row['width'],\n",
    "                    bottom=inner_radius,\n",
    "                    color=color,\n",
    "                    alpha=1.0,\n",
    "                    edgecolor='none',\n",
    "                    zorder=0\n",
    "                )\n",
    "\n",
    "            ax.set_theta_zero_location(\"N\")\n",
    "            ax.set_theta_direction(\"clockwise\")\n",
    "            r_max_dir = grouped_dir['r_plot'].max() + 0.1\n",
    "            ax.set_ylim(0, r_max_dir)\n",
    "\n",
    "            tick_locations = [inner_radius + x for x in [0, 0.5, 1.0, 1.5, 2.0, 2.5]]\n",
    "            ax.set_yticks(tick_locations)\n",
    "            # display y-ticklabels in front of plotted bars\n",
    "            ax.set_yticklabels([f\"{(t - inner_radius)*100:.0f}%\" for t in tick_locations], fontsize=9)\n",
    "            ax.tick_params(axis='y', which='both', direction='out', zorder=3)\n",
    "            ax.set_rlabel_position(15)\n",
    "\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontweight(\"bold\" if label.get_text() == \"100%\" else \"normal\")\n",
    "\n",
    "            ax.set_title(f\"{direction.title()}\", fontsize=18, fontweight='bold')\n",
    "\n",
    "            circle = Circle((0, 0), inner_radius, transform=ax.transData._b, facecolor='white', edgecolor='none', zorder=1)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "            ax.set_xticks(np.deg2rad([0, 90, 180, 270]))\n",
    "            ax.set_xticklabels(['N', 'E', 'S', 'W'], fontsize=10, ha='center')\n",
    "            ax.spines['polar'].set_visible(False)\n",
    "\n",
    "        # Display the distance ratio legend only once\n",
    "        ytick_lines = [\n",
    "            Line2D([0], [0], color=\"gray\", linewidth=1.5, label=\"0%: prediction on landmark\"),\n",
    "            Line2D([0], [0], color=\"gray\", linewidth=1.5, label=\"0 < r < 100%: prediction too short\"),\n",
    "            Line2D([0], [0], color=\"black\", linewidth=1.5, label=\"100%: prediction == true distance\"),\n",
    "            Line2D([0], [0], color=\"gray\", linewidth=1.5, label=\"r > 100%: prediction too long\")\n",
    "        ]\n",
    "\n",
    "        fig.legend(\n",
    "            handles=ytick_lines,\n",
    "            title=\"Trajector distance ratio\",\n",
    "            loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=int(num_directions),\n",
    "            prop={'weight':'bold'}\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(viz_file_name, dpi=500)\n",
    "        plt.show()"
   ],
   "id": "a72816a9c21ad9b2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:55.015899Z",
     "start_time": "2025-06-08T14:25:55.013477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_direction_confusion_matrix(\n",
    "    df,\n",
    "    azimuth_col,\n",
    "    gold_col,\n",
    "    azimuth_to_direction,\n",
    "    compass_dirs\n",
    "):\n",
    "    # Generate predicted direction\n",
    "    df = df.copy()\n",
    "    df['pred_direction'] = df[azimuth_col].apply(azimuth_to_direction)\n",
    "\n",
    "    # Drop rows where either is NaN\n",
    "    mask = df[gold_col].notna() & df['pred_direction'].notna()\n",
    "    filtered = df[mask].copy()\n",
    "\n",
    "    # Convert to string and drop string 'nan'\n",
    "    filtered[gold_col] = filtered[gold_col].astype(str)\n",
    "    filtered['pred_direction'] = filtered['pred_direction'].astype(str)\n",
    "    filtered = filtered[\n",
    "        (filtered[gold_col].str.lower() != 'nan') &\n",
    "        (filtered['pred_direction'].str.lower() != 'nan')\n",
    "    ]\n",
    "\n",
    "    # Keep only valid labels\n",
    "    valid_labels = set(compass_dirs.keys())\n",
    "    filtered = filtered[\n",
    "        filtered[gold_col].isin(valid_labels) &\n",
    "        filtered['pred_direction'].isin(valid_labels)\n",
    "    ]\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    labels = list(compass_dirs.keys())\n",
    "    conf_matrix = confusion_matrix(\n",
    "        filtered[gold_col],\n",
    "        filtered['pred_direction'],\n",
    "        labels=labels\n",
    "    )\n",
    "    # Calculate ratios (percentages)\n",
    "    row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "    # Avoid division by zero\n",
    "    conf_matrix_percentage = np.divide(conf_matrix, row_sums, out=np.zeros_like(conf_matrix, dtype=float), where=row_sums!=0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix_percentage, annot=True, cmap='Blues', fmt='.2f',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Directions')\n",
    "    plt.ylabel('Actual Directions')\n",
    "    plt.title('Confusion Matrix as Percentages')\n",
    "    plt.show()"
   ],
   "id": "1b241810378131ce",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzzy_cell_match_score: 0.825\n",
      "exact_cell_match_score: 0.220\n",
      "cell_overlap_score: 0.608\n",
      "cell_level_accuracy: 0.381\n",
      "cell_level_bias: 0.277\n",
      "accuracy@10: 0.874\n",
      "strict_accuracy@10: 0.843\n",
      "auc: 0.111\n",
      "mean_error_distance: 35.311\n",
      "median_error_distance: 1.110\n",
      "area_zeta: 599.736\n",
      "area_sspb: 0.030\n",
      "average_precision: 0.493\n",
      "average_recall: 0.737\n",
      "average_f1: 0.591\n",
      "distance_zeta: 24.246\n",
      "distance_sspb: 0.304\n",
      "    disaster  fuzzy_cell_match_score  exact_cell_match_score  \\\n",
      "0  landslide                0.750000                0.167526   \n",
      "1      storm                0.880282                0.166667   \n",
      "2      flood                0.881235                0.228029   \n",
      "3  wild fire                0.777215                0.318987   \n",
      "\n",
      "   cell_overlap_score  cell_level_accuracy  cell_level_bias  \n",
      "0            0.543814             0.329897        -0.530928  \n",
      "1            0.652582             0.239437         0.746479  \n",
      "2            0.684086             0.320665         0.641330  \n",
      "3            0.541772             0.648101         0.174684  \n",
      "    disaster  fuzzy_cell_match_score  exact_cell_match_score  \\\n",
      "0  landslide                0.800000                0.189474   \n",
      "1      storm                0.921182                0.172414   \n",
      "2      flood                0.916256                0.251232   \n",
      "3  wild fire                0.875706                0.209040   \n",
      "\n",
      "   cell_overlap_score  cell_level_accuracy  cell_level_bias  \n",
      "0            0.578947             0.363158        -0.478947  \n",
      "1            0.689655             0.251232         0.738916  \n",
      "2            0.748768             0.330049         0.650246  \n",
      "3            0.604520             0.372881         0.231638  \n",
      "    disaster  fuzzy_cell_match_score  exact_cell_match_score  \\\n",
      "0  landslide                0.702020                0.146465   \n",
      "1      storm                0.843049                0.161435   \n",
      "2      flood                0.848624                0.206422   \n",
      "3  wild fire                0.697248                0.408257   \n",
      "\n",
      "   cell_overlap_score  cell_level_accuracy  cell_level_bias  \n",
      "0            0.510101             0.297980        -0.580808  \n",
      "1            0.618834             0.228700         0.753363  \n",
      "2            0.623853             0.311927         0.633028  \n",
      "3            0.490826             0.871560         0.128440  \n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "def calculate_cell_relation_metrics(georelated_df, natural_disasters):\n",
    "    # Initialize dictionary to store metrics for each disaster\n",
    "    metrics_list = []\n",
    "\n",
    "    # Iterate over each natural disaster and compute the required metrics\n",
    "    for disaster in natural_disasters:\n",
    "        disaster_sub_df = georelated_df[georelated_df['natural_disaster'] == disaster]\n",
    "\n",
    "        # Initialize counts\n",
    "        counts = {\n",
    "            'identical': 0,\n",
    "            'parent': 0,\n",
    "            'child': 0,\n",
    "            'coarser_neighbor': 0,\n",
    "            'same_resolution_neighbor': 0,\n",
    "            'finer_neighbor': 0,\n",
    "            'disjoint_same_resolution': 0,\n",
    "            'disjoint_coarser_resolution': 0,\n",
    "            'disjoint_finer_resolution': 0\n",
    "        }\n",
    "\n",
    "        for _, row in disaster_sub_df.iterrows():\n",
    "            relation = row['cell_relation']\n",
    "            if relation in counts:\n",
    "                counts[relation] += 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        total = sum(counts.values())\n",
    "        fuzzy_cell_match_score = 1 - (counts['disjoint_coarser_resolution'] + counts['disjoint_finer_resolution'] + counts['disjoint_same_resolution']) / total if total else 0\n",
    "        exact_cell_match_score = counts['identical'] / total if total else 0\n",
    "        cell_overlap_score = (counts['parent'] + counts['child'] + counts['identical']) / total if total else 0\n",
    "        cell_level_accuracy = (counts['identical'] + counts['disjoint_same_resolution'] + counts['same_resolution_neighbor']) / total if total else 0\n",
    "        count_finer = counts['child'] + counts['finer_neighbor'] + counts['disjoint_finer_resolution']\n",
    "        count_coarser = counts['parent'] + counts['coarser_neighbor'] + counts['disjoint_coarser_resolution']\n",
    "        cell_level_bias = (count_coarser - count_finer) / total if total else 0\n",
    "\n",
    "\n",
    "        # Store the metrics in the dictionary\n",
    "        metrics_list.append({\n",
    "            'disaster': disaster,\n",
    "            'fuzzy_cell_match_score': fuzzy_cell_match_score,\n",
    "            'exact_cell_match_score': exact_cell_match_score,\n",
    "            'cell_overlap_score': cell_overlap_score,\n",
    "            'cell_level_accuracy': cell_level_accuracy,\n",
    "            'cell_level_bias': cell_level_bias,\n",
    "        })\n",
    "\n",
    "    # Convert metrics list to DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    return metrics_df"
   ],
   "id": "a6c66d2bfca3c46b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:43:54.426344Z",
     "start_time": "2025-05-31T15:43:54.424593Z"
    }
   },
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "def calculate_between_distance(row):\n",
    "    if row['between_landmark_2'] is None:\n",
    "        between_distance = row['distance_to_landmark']\n",
    "    else:\n",
    "        between_subj_coords = (row['landmark_latitude'], row['landmark_longitude'])\n",
    "        between_obj = row['between_landmark_2']\n",
    "        between_obj_coords = (between_obj['lat'], between_obj['lng'])\n",
    "        between_distance = geodesic(between_subj_coords, between_obj_coords).meters\n",
    "    return between_distance"
   ],
   "id": "77a09250ad41420a",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T20:08:41.827397Z",
     "start_time": "2025-05-31T20:03:17.479254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Metrics for all runs and aggregate\n",
    "repo_root = git.Repo('.', search_parent_directories=True).working_tree_dir\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "DATA_FOLDER = fr\"{repo_root}/output/georelating/\"\n",
    "RESULT_CSV = os.path.join(DATA_FOLDER, \"model_region_metrics_summary.csv\")\n",
    "ALL_RUNS_CSV = os.path.join(DATA_FOLDER, \"all_run_metrics.csv\")\n",
    "\n",
    "RE_FILENAME = re.compile(\n",
    "    r\"processed_(.+)_(\\d+)_(\\d+)_gandr_([^_]+)\\.json\"\n",
    ")\n",
    "\n",
    "VIP_METRICS = [\n",
    "    (\"auc\", \"auc\"),\n",
    "    (\"precision\", \"average_precision\"),\n",
    "    (\"recall\", \"average_recall\"),\n",
    "    (\"f1\", \"average_f1\"),\n",
    "    (\"distance_zeta\", \"distance_zeta\"),\n",
    "    (\"distance_sspb\", \"distance_sspb\"),\n",
    "    ('fuzzy_cell_match_score', \"fuzzy_cell_match_score\"),\n",
    "    (\"exact_cell_match_score\", \"exact_cell_match_score\"),\n",
    "    ('cell_overlap_score', \"cell_overlap_score\"),\n",
    "    ('cell_level_accuracy', \"cell_level_accuracy\"),\n",
    "    ('cell_level_bias', \"cell_level_bias\")\n",
    "]\n",
    "\n",
    "# ========== DIRECTION CONFUSION MATRIX HANDLING ==========\n",
    "def run_conf_matrix(df, gold_col='spatial_relation', azimuth_col='forward_azimuth'):\n",
    "    dir_labels = list(compass_dirs.keys())\n",
    "    local_df = df.copy()\n",
    "    local_df['pred_direction'] = local_df[azimuth_col].apply(azimuth_to_direction)\n",
    "    # Drop NaNs, enforce string\n",
    "    mask = local_df[gold_col].notna() & local_df['pred_direction'].notna()\n",
    "    filtered = local_df[mask].copy()\n",
    "    filtered[gold_col] = filtered[gold_col].astype(str)\n",
    "    filtered['pred_direction'] = filtered['pred_direction'].astype(str)\n",
    "    filtered = filtered[\n",
    "        (filtered[gold_col].str.lower() != 'nan') &\n",
    "        (filtered['pred_direction'].str.lower() != 'nan')\n",
    "    ]\n",
    "    valid_labels = set(compass_dirs.keys())\n",
    "    filtered = filtered[\n",
    "        filtered[gold_col].isin(valid_labels) &\n",
    "        filtered['pred_direction'].isin(valid_labels)\n",
    "    ]\n",
    "    matrix = confusion_matrix(filtered[gold_col], filtered['pred_direction'], labels=dir_labels)\n",
    "    row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "    # Normalize by row/true label\n",
    "    percentage = np.divide(matrix, row_sums, out=np.zeros_like(matrix, dtype=float), where=row_sums!=0)\n",
    "    return percentage, dir_labels\n",
    "\n",
    "# ========== MAIN SCRIPT ==========\n",
    "files = glob.glob(os.path.join(DATA_FOLDER, \"processed_*_gandr_*.json\"))\n",
    "\n",
    "all_results = []\n",
    "per_prep_stats = {}\n",
    "per_disaster_stats = {}\n",
    "\n",
    "for f in files:\n",
    "    filename = os.path.basename(f)\n",
    "    match = RE_FILENAME.match(filename)\n",
    "    if not match:\n",
    "        print(f\"Skipping {filename} (pattern mismatch)\")\n",
    "        continue\n",
    "    model_name, run_number, run_date, region = match.groups()\n",
    "    try:\n",
    "        df = pd.read_json(f, orient='records')\n",
    "    except Exception as ex:\n",
    "        print(f\"Failed to read {filename}: {ex}\")\n",
    "        continue\n",
    "    df['pred_cell'] = df.apply(safe_latlng_to_cell, axis=1)\n",
    "    df['pred_cell_area'] = df.apply(lambda x: h3.cell_area(x['pred_cell'], unit=\"m^2\") if x['pred_cell'] else None, axis=1)\n",
    "    df['cell_relation'] = df.apply(lambda x: get_cell_relation(x['pred_cell'], x['trajector_cell_index']) if x['pred_cell'] and x['trajector_cell_index'] else None, axis=1)\n",
    "    df[[\"forward_azimuth\", \"pred_distance\"]] = df.apply(calc_azimuth_distance, axis=1)\n",
    "    df['distance_to_landmark'] = df.apply(calculate_between_distance, axis=1)\n",
    "\n",
    "    # ---- Run-level metrics\n",
    "    run_metrics = calculate_metrics(df, k=10)\n",
    "\n",
    "    labels = [\n",
    "        'finer_neighbor', 'parent', 'child', 'coarser_neighbor', 'identical', 'same_resolution_neighbor',\n",
    "        'disjoint_same_resolution', 'disjoint_coarser_resolution', 'disjoint_finer_resolution'\n",
    "    ]\n",
    "\n",
    "    def get_ratios_dict(df):\n",
    "        # Count occurrences of each cell relation\n",
    "        cell_relation_counts = df['cell_relation'].value_counts()\n",
    "        # Ensure order and fill missing labels with 0\n",
    "        cell_relation_ratios = cell_relation_counts.reindex(labels, fill_value=0) / cell_relation_counts.sum()\n",
    "        return cell_relation_ratios.to_dict()\n",
    "\n",
    "    ratios_df = get_ratios_dict(df)\n",
    "\n",
    "    # ---- Confusion matrix\n",
    "    cmatrix, dir_labels = run_conf_matrix(df, gold_col='spatial_relation', azimuth_col='forward_azimuth')\n",
    "\n",
    "    # Collect run-level info for summary\n",
    "    result_row = dict(\n",
    "        model_name=model_name,\n",
    "        run_number=run_number,\n",
    "        run_date=run_date,\n",
    "        region=region,\n",
    "        **run_metrics,\n",
    "        **ratios_df,\n",
    "        conf_matrix=cmatrix,\n",
    "        conf_labels=dir_labels\n",
    "    )\n",
    "    all_results.append(result_row)\n",
    "\n",
    "    # ---- Per-PREPOSITION metrics for this file\n",
    "    for prep in df[\"spatial_relation\"].dropna().unique():\n",
    "        subdf = df[df[\"spatial_relation\"] == prep]\n",
    "        if subdf.empty:\n",
    "            continue\n",
    "        prep_metrics = calculate_metrics(subdf, k=10)\n",
    "        key = (model_name, region, prep)\n",
    "        if key not in per_prep_stats:\n",
    "            per_prep_stats[key] = {m[0]: [] for m in VIP_METRICS}\n",
    "        for (colname, dictkey) in VIP_METRICS:\n",
    "            per_prep_stats[key][colname].append(prep_metrics[dictkey])\n",
    "\n",
    "    # ---- Per-DISASTER metrics for this file\n",
    "    for disaster in df[\"natural_disaster\"].dropna().unique():\n",
    "        subdf = df[df[\"natural_disaster\"] == disaster]\n",
    "        if subdf.empty:\n",
    "            continue\n",
    "        disaster_metrics = calculate_metrics(subdf, k=10)\n",
    "        key = (model_name, region, disaster)\n",
    "        if key not in per_disaster_stats:\n",
    "            per_disaster_stats[key] = {m[0]: [] for m in VIP_METRICS}\n",
    "        for (colname, dictkey) in VIP_METRICS:\n",
    "            per_disaster_stats[key][colname].append(disaster_metrics[dictkey])\n",
    "\n",
    "# Compile all per-run metrics\n",
    "all_runs_df = pd.DataFrame(all_results)\n",
    "all_runs_df.to_csv(ALL_RUNS_CSV, index=False)\n",
    "\n",
    "# ========== AGGREGATE BY MODEL/REGION ==========\n",
    "groupcols = [\"model_name\", \"region\"]\n",
    "metriccols = [col for col in all_runs_df.columns if col not in groupcols + [\"run_number\", \"run_date\", \"conf_matrix\", \"conf_labels\"]]\n",
    "\n",
    "agg_rows = []\n",
    "grouped = all_runs_df.groupby(groupcols)\n",
    "for (model, region), group in grouped:\n",
    "    agg = {\n",
    "        \"model_name\": model,\n",
    "        \"region\": region,\n",
    "        \"n_runs\": len(group)\n",
    "    }\n",
    "    for mcol in metriccols:\n",
    "        vals = group[mcol].dropna()\n",
    "        if len(vals) > 1:\n",
    "            mean = vals.mean()\n",
    "            ci95 = stats.t.interval(0.95, len(vals)-1, loc=mean, scale=vals.std(ddof=1)/np.sqrt(len(vals)))\n",
    "            agg[f\"{mcol}_mean\"] = mean\n",
    "            agg[f\"{mcol}_ci95_lower\"] = ci95[0]\n",
    "            agg[f\"{mcol}_ci95_upper\"] = ci95[1]\n",
    "        elif len(vals) == 1:\n",
    "            agg[f\"{mcol}_mean\"] = float(vals.iloc[0])\n",
    "            agg[f\"{mcol}_ci95_lower\"] = np.nan\n",
    "            agg[f\"{mcol}_ci95_upper\"] = np.nan\n",
    "        else:\n",
    "            agg[f\"{mcol}_mean\"] = np.nan\n",
    "            agg[f\"{mcol}_ci95_lower\"] = np.nan\n",
    "            agg[f\"{mcol}_ci95_upper\"] = np.nan\n",
    "    agg_rows.append(agg)\n",
    "\n",
    "# Aggregate metrics across all regions for each model\n",
    "agg_over_regions = all_runs_df.drop(\"region\", axis=1).groupby(\"model_name\")\n",
    "for model, group in agg_over_regions:\n",
    "    agg = {\n",
    "        \"model_name\": model,\n",
    "        \"region\": \"US_and_EU\",\n",
    "        \"n_runs\": len(group)\n",
    "    }\n",
    "    for mcol in metriccols:\n",
    "        vals = group[mcol].dropna()\n",
    "        if len(vals) > 1:\n",
    "            mean = vals.mean()\n",
    "            ci95 = stats.t.interval(0.95, len(vals)-1, loc=mean, scale=vals.std(ddof=1)/np.sqrt(len(vals)))\n",
    "            agg[f\"{mcol}_mean\"] = mean\n",
    "            agg[f\"{mcol}_ci95_lower\"] = ci95[0]\n",
    "            agg[f\"{mcol}_ci95_upper\"] = ci95[1]\n",
    "        elif len(vals) == 1:\n",
    "            agg[f\"{mcol}_mean\"] = float(vals.iloc[0])\n",
    "            agg[f\"{mcol}_ci95_lower\"] = np.nan\n",
    "            agg[f\"{mcol}_ci95_upper\"] = np.nan\n",
    "        else:\n",
    "            agg[f\"{mcol}_mean\"] = np.nan\n",
    "            agg[f\"{mcol}_ci95_lower\"] = np.nan\n",
    "            agg[f\"{mcol}_ci95_upper\"] = np.nan\n",
    "    agg_rows.append(agg)\n",
    "\n",
    "agg_df = pd.DataFrame(agg_rows)\n",
    "\n",
    "# ========== AGGREGATE PER-PREPOSITION METRICS ==========\n",
    "colstubs = []\n",
    "for idx, row in agg_df.iterrows():\n",
    "    model = row[\"model_name\"]\n",
    "    region = row[\"region\"]\n",
    "    for (m, r, prep), metric_dict in per_prep_stats.items():\n",
    "        if m == model and (r == region):\n",
    "            for colname, _ in VIP_METRICS:\n",
    "                values = np.array(metric_dict[colname])\n",
    "                values = values[~np.isnan(values)]\n",
    "                colstub = f\"{prep}_{colname}\"\n",
    "                colstubs.extend([f\"{colstub}_mean\", f\"{colstub}_ci95_upper\", f\"{colstub}_ci95_lower\"])\n",
    "                if len(values) > 1:\n",
    "                    mean = values.mean()\n",
    "                    ci95 = stats.t.interval(0.95, len(values)-1, loc=mean, scale=values.std(ddof=1)/np.sqrt(len(values)))\n",
    "                elif len(values) == 1:\n",
    "                    mean = float(values[0])\n",
    "                    ci95 = (np.nan, np.nan)\n",
    "                else:\n",
    "                    mean = np.nan\n",
    "                    ci95 = (np.nan, np.nan)\n",
    "                agg_df.at[idx, f\"{colstub}_mean\"] = mean\n",
    "                agg_df.at[idx, f\"{colstub}_ci95_lower\"] = ci95[0]\n",
    "                agg_df.at[idx, f\"{colstub}_ci95_upper\"] = ci95[1]\n",
    "for idx, row in agg_df.iterrows():\n",
    "    model = row[\"model_name\"]\n",
    "    region = row[\"region\"]\n",
    "    if region != \"US_and_EU\":\n",
    "        continue\n",
    "    # iterate over the columns in agg_df\n",
    "    for series_name, series in agg_df.items():\n",
    "        if series_name in set(colstubs):\n",
    "            regional_values = agg_df[series_name].loc[agg_df['model_name'] == model]\n",
    "            agg_df.at[idx, series_name] = regional_values.mean()\n",
    "\n",
    "\n",
    "# ========== AGGREGATE PER-DISASTER METRICS ==========\n",
    "for idx, row in agg_df.iterrows():\n",
    "    model = row[\"model_name\"]\n",
    "    region = row[\"region\"]\n",
    "    for (m, r, disaster), metric_dict in per_disaster_stats.items():\n",
    "        if m == model and (r == region or region == \"US_and_EU\"):\n",
    "            for colname, _ in VIP_METRICS:\n",
    "                values = np.array(metric_dict[colname])\n",
    "                values = values[~np.isnan(values)]\n",
    "                colstub = f\"{disaster}_{colname}\"\n",
    "                colstubs.extend([f\"{colstub}_mean\", f\"{colstub}_ci95_upper\", f\"{colstub}_ci95_lower\"])\n",
    "                if len(values) > 1:\n",
    "                    mean = values.mean()\n",
    "                    ci95 = stats.t.interval(0.95, len(values)-1, loc=mean, scale=values.std(ddof=1)/np.sqrt(len(values)))\n",
    "                elif len(values) == 1:\n",
    "                    mean = float(values[0])\n",
    "                    ci95 = (np.nan, np.nan)\n",
    "                else:\n",
    "                    mean = np.nan\n",
    "                    ci95 = (np.nan, np.nan)\n",
    "                agg_df.at[idx, f\"{colstub}_mean\"] = mean\n",
    "                agg_df.at[idx, f\"{colstub}_ci95_lower\"] = ci95[0]\n",
    "                agg_df.at[idx, f\"{colstub}_ci95_upper\"] = ci95[1]\n",
    "for idx, row in agg_df.iterrows():\n",
    "    model = row[\"model_name\"]\n",
    "    region = row[\"region\"]\n",
    "    if region != \"US_and_EU\":\n",
    "        continue\n",
    "    # iterate over the columns in agg_df\n",
    "    for series_name, series in agg_df.items():\n",
    "        if series_name in set(colstubs):\n",
    "            regional_values = agg_df[series_name].loc[agg_df['model_name'] == model]\n",
    "            agg_df.at[idx, series_name] = regional_values.mean()\n",
    "# ========== AGGREGATE CONFUSION MATRICES ==========\n",
    "conf_by_group = {}\n",
    "for (model, region), group in all_runs_df.groupby([\"model_name\", \"region\"]):\n",
    "    conf_matrices = [row[\"conf_matrix\"] for _, row in group.iterrows() if \"conf_matrix\" in row and row[\"conf_matrix\"] is not None]\n",
    "    if conf_matrices:\n",
    "        conf_by_group[(model, region)] = np.stack(conf_matrices, axis=0)  # shape: (R, L, L)\n",
    "\n",
    "for idx, row in agg_df.iterrows():\n",
    "    model = row[\"model_name\"]\n",
    "    region = row[\"region\"]\n",
    "    if (model, region) not in conf_by_group:\n",
    "        continue\n",
    "    mats = conf_by_group[(model, region)]  # shape (R, L, L)\n",
    "    n_runs, L, _ = mats.shape\n",
    "    # Use the common compass label order (should be identical across runs)\n",
    "    dir_labels = all_runs_df[\n",
    "        (all_runs_df[\"model_name\"] == model) & (all_runs_df[\"region\"] == region)\n",
    "    ][\"conf_labels\"].iloc[0]\n",
    "    for i, gold_dir in enumerate(dir_labels):\n",
    "        for j, pred_dir in enumerate(dir_labels):\n",
    "            vals = mats[:, i, j]\n",
    "            vals = vals[~np.isnan(vals)]\n",
    "            if len(vals) > 1:\n",
    "                mean = vals.mean()\n",
    "            elif len(vals) == 1:\n",
    "                mean = float(vals[0])\n",
    "            else:\n",
    "                mean = np.nan\n",
    "            col_base = f\"conf_{gold_dir}_{pred_dir}\"\n",
    "            agg_df.at[idx, f\"{col_base}_mean\"] = mean\n",
    "\n",
    "agg_df.to_csv(RESULT_CSV, index=False)\n",
    "print(\"Saved summary to\", RESULT_CSV)\n",
    "print(\"Saved per-run metrics to\", ALL_RUNS_CSV)"
   ],
   "id": "abf8cb4585a78b2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to /Users/kaimoltzen/academiccloudsync/Uni/Master/5_WS24_25-MA/geoparse-natural-disasters-with-llms/output/georelating/model_region_metrics_summary.csv\n",
      "Saved per-run metrics to /Users/kaimoltzen/academiccloudsync/Uni/Master/5_WS24_25-MA/geoparse-natural-disasters-with-llms/output/georelating/all_run_metrics.csv\n"
     ]
    }
   ],
   "execution_count": 155
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
